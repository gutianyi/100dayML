{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas_profiling as ppf\n",
    "# dataset.info()\n",
    "# report = ppf.ProfileReport(dataset[['Adj Close','Volume']])\n",
    "# report.to_file('report_AdjCloseVolume.md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pylab import rcParams\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler ##数据归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data,m,n):\n",
    "    '''\n",
    "    data: the dataframe of stock price\n",
    "    m: 前m天预测\n",
    "    n: 预测几天\n",
    "    '''\n",
    "    minMax = MinMaxScaler()    \n",
    "    data_transformed = minMax.fit_transform(data)\n",
    "\n",
    "    adj_close = data[\"Adj Close\"].tolist()\n",
    "    adj_volume = data_transformed[:,-2:]\n",
    "    #\n",
    "    res_X = []\n",
    "    res_y = []\n",
    "    \n",
    "    for i in range(0,len(adj_close)-m-n+1):\n",
    "        res_X.append(adj_volume[i:i+m])\n",
    "        res_y.append(adj_close[i+m:i+m+n])\n",
    "    return res_X,res_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('/Users/elvis/ITProjects/GitHub/PythonTask/100dayML/100_day_ml_py/ml_project/raw_price_train/1_r_price_train.csv',index_col='Date')\n",
    "dataset.index = pd.to_datetime(dataset.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = preprocess(dataset,14,7)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,train_size=0.7)\n",
    "# print((np.array(X_train)).shape)\n",
    "# print((np.array(y_train)).shape)\n",
    "# print((np.array(X)).shape)\n",
    "# print((np.array(y)).shape)\n",
    "# print((np.array(y[-1])).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-9e9490d2dbfb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     20\u001b[0m test_loader = Data.DataLoader(\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch_dataset\u001b[0m\u001b[0;34m,\u001b[0m      \u001b[0;31m# torch TensorDataset format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m      \u001b[0;31m# mini batch size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m               \u001b[0;31m# 要不要打乱数据 (打乱比较好)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "import torch.utils.data as Data\n",
    "\n",
    "tensor_x_train = torch.Tensor(X_train)\n",
    "tensor_y_train = torch.Tensor(y_train)\n",
    "\n",
    "tensor_x_test = torch.Tensor(X_test)\n",
    "tensor_y_test = torch.Tensor(y_test)\n",
    "\n",
    "# 先转换成 torch 能识别的 Dataset\n",
    "torch_train_dataset = Data.TensorDataset(tensor_x_train, tensor_y_train)\n",
    "torch_test_dataset = Data.TensorDataset(tensor_x_test, tensor_y_test)\n",
    "\n",
    "# 把 dataset 放入 DataLoader\n",
    "train_loader = Data.DataLoader(\n",
    "    dataset=torch_train_dataset,      # torch TensorDataset format\n",
    "    batch_size=100,      # mini batch size\n",
    "    shuffle=True,               # 要不要打乱数据 (打乱比较好)\n",
    "    num_workers=2,              # 多线程来读数据\n",
    ")\n",
    "test_loader = Data.DataLoader(\n",
    "    dataset=torch_test_dataset,      # torch TensorDataset format\n",
    "    batch_size=100,      # mini batch size\n",
    "    shuffle=True,               # 要不要打乱数据 (打乱比较好)\n",
    "    num_workers=2,              # 多线程来读数据\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.rnn = nn.LSTM(  # if use nn.RNN(), it hardly learns\n",
    "            input_size=2,\n",
    "            hidden_size=64,         # rnn hidden unit\n",
    "            num_layers=1,           # number of rnn layer\n",
    "            batch_first=True,       # input & output will has batch size as 1s dimension. e.g. (batch, time_step, input_size)\n",
    "        )\n",
    "        \n",
    "\n",
    "        self.out = nn.Linear(64, 7)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape (batch, time_step, input_size)\n",
    "        # r_out shape (batch, time_step, output_size)\n",
    "        # h_n shape (n_layers, batch, hidden_size)\n",
    "        # h_c shape (n_layers, batch, hidden_size)\n",
    "        r_out, (h_n, h_c) = self.rnn(x, None)   # None represents zero initial hidden state\n",
    "\n",
    "        # choose r_out at the last time step\n",
    "        out = self.out(r_out[:, -1, :])\n",
    "        return out\n",
    "    \n",
    "# class RNN(nn.Module):\n",
    "#     def __init__(self,input_dim, hidden_dim, output_dim):\n",
    "#         super().__init__()\n",
    "#         self.lstm = nn.LSTM(input_dim, hidden_dim,\n",
    "#                             num_layers=2,\n",
    "#                             bidirectional=True,\n",
    "#                             dropout=0.2)\n",
    "#         self.fc = nn.Sequential(\n",
    "#             nn.Linear(hidden_dim*2, 256),\n",
    "#             nn.Dropout(0.2),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(256,output_dim),\n",
    "#         )\n",
    "\n",
    "#     def forward(self, input_x):\n",
    "#         packed_output, (hidden, cell) = self.lstm(input_x)\n",
    "#         output = self.fc(torch.cat((hidden[-2,:,:],hidden[-1,:,:]),dim=1)).squeeze()\n",
    "#         return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN()\n",
    "import torch.optim as optim\n",
    "\n",
    "# 定义优化器\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "loss_func = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "def train(model, loader, optimizer, loss_func):\n",
    "    model.train()\n",
    "\n",
    "    for step, (batch_x, batch_y) in enumerate(loader):  # 每一步 loader 释放一小批数据用来学习\n",
    "        # 训练的地方...\n",
    "        batch_x = batch_x.view(-1, 14, 2)              # reshape x to (batch, time_step, input_size)\n",
    "        batch_y = batch_y.view(-1,7)\n",
    "        output = model(batch_x)\n",
    "        loss = loss_func(output, batch_y)                   # cross entropy loss\n",
    "        \n",
    "        optimizer.zero_grad()                           # clear gradients for this training step\n",
    "        loss.backward()                                 # backpropagation, compute gradients\n",
    "        optimizer.step()\n",
    "        \n",
    "        acc = mean_squared_error(batch_y.numpy().tolist(),output.detach().numpy())\n",
    "        \n",
    "    return loss.data.numpy(), acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不用优化器了\n",
    "def evaluate(model, loader, loss_func):\n",
    "    # 转成测试模式，冻结dropout层或其他层\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for step, (batch_x, batch_y) in enumerate(loader):  # 每一步 loader 释放一小批数据用来学习\n",
    "\n",
    "            batch_x = batch_x.view(-1, 14, 2)              # reshape x to (batch, time_step, input_size)\n",
    "            batch_y = batch_y.view(-1,7)\n",
    "            output = model(batch_x)\n",
    "            loss = loss_func(output, batch_y)\n",
    "            acc = mean_squared_error(batch_y.numpy().tolist(),output.detach().numpy())\n",
    "\n",
    "        # 调回训练模式\n",
    "        model.train()\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_test_mse = float('inf')\n",
    "for epoch in range(10):   # 训练所有!整套!数据 10 次\n",
    "    train_loss, train_mse = train(model, torch_train_dataset, optimizer, loss_func)\n",
    "    test_mse = evaluate(model, torch_test_dataset, loss_func)\n",
    "    \n",
    "    \n",
    "    if test_mse < best_test_mse:\n",
    "        best_test_mse = test_mse\n",
    "        torch.save(model.state_dict(), 'stock-rnn-model.pt')\n",
    "        \n",
    "    if epoch> 0 :\n",
    "        print('Epoch: ', epoch, '| train_loss: ', train_loss, '| train_mse x: ', train_mse, '| test_mse x: ', test_mse)\n",
    "        # 打出来一些数据\n",
    "#         print('Epoch: ', epoch, '| Step: ', step, '| batch x: ',\n",
    "#               batch_x.numpy(), '| batch y: ', batch_y.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_x = [1,2,3,5,6]\n",
    "list_x[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
