{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入夸夸语料对\n",
    "q_list = []\n",
    "a_list = []\n",
    "with open('kuakua_qa_pairs.txt', 'r', encoding='utf-8') as inf:\n",
    "    for line in inf:\n",
    "        items = line.strip('\\r\\n').split('\\t')\n",
    "        q_list.append(items[0])\n",
    "        a_list.append(items[1])    \n",
    "        \n",
    "#生成字典\n",
    "kuakua_dict = {}\n",
    "for i in range(len(q_list)):\n",
    "    if (q_list[i] in kuakua_dict) == False:\n",
    "        kuakua_dict[q_list[i]] = []\n",
    "        kuakua_dict[q_list[i]].append(a_list[i])\n",
    "    if (q_list[i] in kuakua_dict) == True:\n",
    "        kuakua_dict[q_list[i]].append(a_list[i])\n",
    "\n",
    "        \n",
    "#导入停用词表\n",
    "stop_word_file = 'stop_ch.txt'\n",
    "stopwords = [line.strip() for line in open(stop_word_file, encoding='UTF-8').readlines()]\n",
    "\n",
    "#问句语料切句\n",
    "import jieba\n",
    "q_set = list(set(q_list))\n",
    "q_jieba_list = []\n",
    "for i in range(len(q_set)):\n",
    "    temp = list(jieba.cut(q_set[i]))\n",
    "    temp = [x for x in temp if (x in stopwords) == False]\n",
    "    q_jieba_list.append(temp)\n",
    "\n",
    "#导入词向量模型\n",
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec.load(\"model/word2vec_kuakua.model\")\n",
    "\n",
    "#WMD距离匹配初始化\n",
    "from gensim.similarities import WmdSimilarity\n",
    "num_best = 1\n",
    "instance = WmdSimilarity(q_jieba_list , model, num_best)\n",
    "\n",
    "query = list(jieba.cut(\"我的字写的好看吗\"))\n",
    "query = [x for x in query if (x in stopwords) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['字', '写', '好看']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sims = instance[query]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53, 0.8768347423157669)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = list(jieba.cut(\"我怀孕了\"))\n",
    "query = [x for x in query if (x in stopwords) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_list = kuakua_dict[q_set[sims[0][0]]]\n",
    "re_reply_msg = choice(candidate_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'好看！羡慕！'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_reply_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "from random import choice\n",
    "\n",
    "\n",
    "#导入夸夸语料对\n",
    "q_list = []\n",
    "a_list = []\n",
    "with open('kuakua_qa_pairs.txt', 'r', encoding='utf-8') as inf:\n",
    "    for line in inf:\n",
    "        items = line.strip('\\r\\n').split('\\t')\n",
    "        q_list.append(items[0])\n",
    "        a_list.append(items[1])    \n",
    "        \n",
    "#生成字典\n",
    "kuakua_dict = {}\n",
    "for i in range(len(q_list)):\n",
    "    if (q_list[i] in kuakua_dict) == False:\n",
    "        kuakua_dict[q_list[i]] = []\n",
    "        kuakua_dict[q_list[i]].append(a_list[i])\n",
    "    if (q_list[i] in kuakua_dict) == True:\n",
    "        kuakua_dict[q_list[i]].append(a_list[i])\n",
    "\n",
    "        \n",
    "#导入停用词表\n",
    "stop_word_file = 'stop_ch.txt'\n",
    "stopwords = [line.strip() for line in open(stop_word_file, encoding='UTF-8').readlines()]\n",
    "\n",
    "#问句语料切句\n",
    "import jieba\n",
    "q_set = list(set(q_list))\n",
    "q_jieba_list = []\n",
    "for i in range(len(q_set)):\n",
    "    temp = list(jieba.cut(q_set[i]))\n",
    "    temp = [x for x in temp if (x in stopwords) == False]\n",
    "    q_jieba_list.append(temp)\n",
    "\n",
    "#导入词向量模型\n",
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec.load(\"model/word2vec_kuakua.model\")\n",
    "\n",
    "#WMD距离匹配初始化\n",
    "from gensim.similarities import WmdSimilarity\n",
    "num_best = 1\n",
    "instance = WmdSimilarity(q_jieba_list , model, num_best)\n",
    "\n",
    "server = socket.socket()\n",
    "host = socket.gethostname()\n",
    "port = 8888\n",
    "server.bind((host, port))\n",
    "\n",
    "server.listen(5)\n",
    "while True:\n",
    "    print(\"Waiting for client to conect\")\n",
    "    client, addr = server.accept()\n",
    "    print(\"Clinet connected, the address is {}\".format(addr))\n",
    "    client.send(bytes(\"你好，我是金圣水傻逼夸夸机器人。请问你是谁？\", encoding = \"UTF-8\"))\n",
    "    while True:\n",
    "        reply = str(client.recv(1024), encoding = \"UTF-8\")\n",
    "        re_reply_msg = \"你好 \" + reply + \"，你可真是个傻逼。\"  + \"快让我抹了蜜的小嘴夸夸你吧\"\n",
    "        client.send(bytes(re_reply_msg, encoding = \"UTF-8\"))\n",
    "        while True:\n",
    "            reply = str(client.recv(1024), encoding = \"UTF-8\")\n",
    "            print(\"Client : {}\".format(reply))\n",
    "            #对客户REPLY做的操作，WMD距离的匹配\n",
    "            query = list(jieba.cut(reply))\n",
    "            query = [x for x in query if (x in stopwords) == False]\n",
    "            sims = instance[query]\n",
    "            if simi != []:\n",
    "                candidate_list = kuakua_dict[q_set[sims[0][0]]]\n",
    "                re_reply_msg = choice(candidate_list)\n",
    "                client.send(bytes(re_reply_msg, encoding = \"UTF-8\"))\n",
    "            else:\n",
    "                re_reply_msg = \"connecting...\"\n",
    "                client.send(bytes(re_reply_msg, encoding = \"UTF-8\"))\n",
    "                url = \"http://www.baidu.com/s?wd=\" + urllib.parse.quote(reply)\n",
    "\n",
    "                headers={\"Accept\": \"text/html, application/xhtml+xml, image/jxr, */*\",\n",
    "\n",
    "                         \"Accept - Encoding\": \"gzip, deflate, br\",\n",
    "\n",
    "                         \"Accept - Language\": \"zh - CN\",\n",
    "\n",
    "                         \"Connection\": \"Keep - Alive\",\n",
    "                         \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36 Edge/16.16299\",\n",
    "                         \"referer\":\"baidu.com\"}\n",
    "                cookie_jar = http.cookiejar.CookieJar()\n",
    "                opener = urllib.request.build_opener(urllib.request.HTTPCookieProcessor(cookie_jar))\n",
    "                headall=[]\n",
    "                for key,value in headers.items():\n",
    "                    item=(key,value)\n",
    "                    headall.append(item)\n",
    "                    opener.addheaders=headall\n",
    "                    urllib.request.install_opener(opener)\n",
    "                    data = urllib.request.urlopen(url).read().decode('utf-8')\n",
    "                    soup = BeautifulSoup(data,'html.parser')\n",
    "                    time.sleep(10)\n",
    "                if soup.find_all('h3',class_='t') != []:\n",
    "                    re_reply_msg = choice(soup.find_all('h3',class_='t')[0].find(\"a\").get_text())\n",
    "                    client.send(bytes(re_reply_msg, encoding = \"UTF-8\"))\n",
    "                    re_reply_msg = choice(soup.find_all('h3',class_='t')[0].find(\"a\").get(\"href\"))\n",
    "                    client.send(bytes(re_reply_msg, encoding = \"UTF-8\"))\n",
    "                else:\n",
    "                    headall=[]\n",
    "                    for key,value in headers.items():\n",
    "                        item=(key,value)\n",
    "                        headall.append(item)\n",
    "                        opener.addheaders=headall\n",
    "                        urllib.request.install_opener(opener)\n",
    "                        data = urllib.request.urlopen(url).read().decode('utf-8')\n",
    "                        soup = BeautifulSoup(data,'html.parser')\n",
    "                        time.sleep(10)\n",
    "                        if soup.find_all('h3',class_='t') != []:\n",
    "                            re_reply_msg = choice(soup.find_all('h3',class_='t')[0].find(\"a\").get_text())\n",
    "                            client.send(bytes(re_reply_msg, encoding = \"UTF-8\"))\n",
    "                            re_reply_msg = choice(soup.find_all('h3',class_='t')[0].find(\"a\").get(\"href\"))\n",
    "                            client.send(bytes(re_reply_msg, encoding = \"UTF-8\"))\n",
    "                        else:\n",
    "                            re_reply_msg = \"sorry connecting failed\"\n",
    "                            client.send(bytes(re_reply_msg, encoding = \"UTF-8\"))\n",
    "                            \n",
    "                    \n",
    "                \n",
    "\n",
    "        \n",
    "    client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                if soup.find_all('h3',class_='t') != []:\n",
    "                    title = choice(soup.find_all('h3',class_='t')[0].find(\"a\").get_text())\n",
    "                    url = choice(soup.find_all('h3',class_='t')[0].find(\"a\").get(\"href\"))\n",
    "                    re_reply_msg = \"connecting...\" + \"\\n\" + title + \"\\n\" + url\n",
    "                    client.send(bytes(re_reply_msg, encoding = \"UTF-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request,parse\n",
    "import urllib\n",
    "import http.cookiejar\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://www.baidu.com/s?wd=\" + urllib.parse.quote(\"我怀孕了\")\n",
    "\n",
    "headers={\"Accept\": \"text/html, application/xhtml+xml, image/jxr, */*\",\n",
    "\n",
    "         \"Accept - Encoding\": \"gzip, deflate, br\",\n",
    "\n",
    "         \"Accept - Language\": \"zh - CN\",\n",
    "\n",
    "         \"Connection\": \"Keep - Alive\",\n",
    "         \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36 Edge/16.16299\",\n",
    "         \"referer\":\"baidu.com\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cookie_jar = http.cookiejar.CookieJar()\n",
    "opener = urllib.request.build_opener(urllib.request.HTTPCookieProcessor(cookie_jar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "headall=[]\n",
    "for key,value in headers.items():\n",
    "    item=(key,value)\n",
    "    headall.append(item)\n",
    "opener.addheaders=headall\n",
    "urllib.request.install_opener(opener)\n",
    "data = urllib.request.urlopen(url).read().decode('utf-8')\n",
    "soup = BeautifulSoup(data,'html.parser')\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'女人说“我怀孕了”,会让男人原形毕露吗?听听这5个女人的经历'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('h3',class_='t')[0].find(\"a\").get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('h3',class_='t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<!DOCTYPE html>\n",
       "\n",
       "<html lang=\"zh-CN\">\n",
       "<head>\n",
       "<meta charset=\"utf-8\"/>\n",
       "<title>百度安全验证</title>\n",
       "<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n",
       "<meta content=\"yes\" name=\"apple-mobile-web-app-capable\"/>\n",
       "<meta content=\"black\" name=\"apple-mobile-web-app-status-bar-style\"/>\n",
       "<meta content=\"width=device-width, user-scalable=no, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0\" name=\"viewport\"/>\n",
       "<meta content=\"telephone=no, email=no\" name=\"format-detection\"/>\n",
       "<link href=\"https://www.baidu.com/favicon.ico\" rel=\"shortcut icon\" type=\"image/x-icon\"/>\n",
       "<link href=\"https://www.baidu.com/img/baidu.svg\" mask=\"\" rel=\"icon\" sizes=\"any\"/>\n",
       "<meta content=\"IE=Edge\" http-equiv=\"X-UA-Compatible\"/>\n",
       "<meta content=\"upgrade-insecure-requests\" http-equiv=\"Content-Security-Policy\"/>\n",
       "<link href=\"https://wappass.bdimg.com/static/touch/css/api/mkdjump_8befa48.css\" rel=\"stylesheet\">\n",
       "</link></head>\n",
       "<body>\n",
       "<div class=\"timeout hide\">\n",
       "<div class=\"timeout-img\"></div>\n",
       "<div class=\"timeout-title\">网络不给力，请稍后重试</div>\n",
       "<button class=\"timeout-button\" type=\"button\">返回首页</button>\n",
       "</div>\n",
       "<div class=\"timeout-feedback hide\">\n",
       "<div class=\"timeout-feedback-icon\"></div>\n",
       "<p class=\"timeout-feedback-title\">问题反馈</p>\n",
       "</div>\n",
       "<script src=\"https://wappass.baidu.com/static/machine/js/api/mkd.js\"></script>\n",
       "<script src=\"https://wappass.bdimg.com/static/touch/js/mkdjump_2e06726.js\"></script>\n",
       "</body>\n",
       "</html><!--33231357770891408138112623-->\n",
       "<script> var _trace_page_logid = 3323135777; </script>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for result_table in soup.find_all('h3',class_='t'):\n",
    "\n",
    "    a_click = result_tableC;\n",
    "\n",
    "    print( \"-----标题----\\n\" + a_click.get_text())  # 标题\n",
    "    print(\"----链接----\\n\" + str(a_click.get(\"href\")))  # 链接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                        title_1 = choice(soup.find_all('h3',class_='t')[0].find(\"a\").get_text())\n",
    "                        url_1 = choice(soup.find_all('h3',class_='t')[0].find(\"a\").get(\"href\"))\n",
    "                        title_2 = choice(soup.find_all('h3',class_='t')[1].find(\"a\").get_text())\n",
    "                        url_2 = choice(soup.find_all('h3',class_='t')[1].find(\"a\").get(\"href\"))\n",
    "                        re_reply_msg = \"connecting...\" + \"\\n\" + title_1 + \"\\n\" + url_1 + title_2 + \"\\n\" + url_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                else:\n",
    "                    headall=[]\n",
    "                    for key,value in headers.items():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                    headall=[]\n",
    "                    for key,value in headers.items():\n",
    "                        item=(key,value)\n",
    "                        headall.append(item)\n",
    "                        opener.addheaders=headall\n",
    "                        urllib.request.install_opener(opener)\n",
    "                        data = urllib.request.urlopen(url).read().decode('utf-8')\n",
    "                        soup = BeautifulSoup(data,'html.parser')\n",
    "                        time.sleep(10)\n",
    "                    if soup.find_all('h3',class_='t') != []:\n",
    "                        title_1 = choice(soup.find_all('h3',class_='t')[0].find(\"a\").get_text())\n",
    "                        url_1 = choice(soup.find_all('h3',class_='t')[0].find(\"a\").get(\"href\"))\n",
    "                        title_2 = choice(soup.find_all('h3',class_='t')[1].find(\"a\").get_text())\n",
    "                        url_2 = choice(soup.find_all('h3',class_='t')[1].find(\"a\").get(\"href\"))\n",
    "                        re_reply_msg = \"connecting...\" + \"\\n\" + title_1 + \"\\n\" + url_1 + title_2 + \"\\n\" + url_2\n",
    "                        client.send(bytes(re_reply_msg, encoding = \"UTF-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                if soup.find_all('h3',class_='t') != []:\n",
    "                    title_1 = choice(soup.find_all('h3',class_='t')[0].find(\"a\").get_text())\n",
    "                    url_1 = choice(soup.find_all('h3',class_='t')[0].find(\"a\").get(\"href\"))\n",
    "                    title_2 = choice(soup.find_all('h3',class_='t')[1].find(\"a\").get_text())\n",
    "                    url_2 = choice(soup.find_all('h3',class_='t')[1].find(\"a\").get(\"href\"))\n",
    "                    re_reply_msg = \"connecting...\" + \"\\n\" + title_1 + \"\\n\" + url_1 + title_2 + \"\\n\" + url_2\n",
    "                    client.send(bytes(re_reply_msg, encoding = \"UTF-8\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
